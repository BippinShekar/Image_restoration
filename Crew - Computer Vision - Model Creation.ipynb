{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0040f16",
   "metadata": {},
   "source": [
    "## Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eb4aee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24103fc3",
   "metadata": {},
   "source": [
    "## Loading the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1dfa22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paths for blur\n",
    "path_to_X_blur_train = './data/X/train'\n",
    "path_to_X_blur_test = './data/X/test'\n",
    "path_to_Y_blur_train= './data/Y/train'\n",
    "path_to_Y_blur_test = './data/Y/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04e2f690",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paths for noise\n",
    "path_to_X_noise_train = './data_noise/X/train'\n",
    "path_to_X_noise_test =  './data_noise/X/test'\n",
    "path_to_Y_noise_train= './data_noise/Y/train'\n",
    "path_to_Y_noise_test = './data_noise/Y/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7bb0d0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paths for scratched\n",
    "path_to_X_scratch_train = './data_scratch/X/train'\n",
    "path_to_X_scratch_test = './data_scratch/X/test'\n",
    "path_to_Y_scratch_train= './data_scratch/Y/train'\n",
    "path_to_Y_scratch_test = './data_scratch/Y/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c67f1eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path for water_spilled\n",
    "path_to_X_water_train = './data_water_spilled/X/train'\n",
    "path_to_X_water_test = './data_water_spilled/X/test'\n",
    "path_to_Y_water_train = './data_water_spilled/Y/train'\n",
    "path_to_Y_water_test= './data_water_spilled/Y/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e94e199",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Writing a loading function\n",
    "def loader(paths,loaded):\n",
    "    for image in os.scandir(paths):\n",
    "        loaded.append(np.load(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3b32f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Blur Data\n",
    "x_train_blur,x_test_blur,y_train_blur,y_test_blur =[],[],[],[]\n",
    "loader(path_to_X_blur_train,x_train_blur)\n",
    "loader(path_to_Y_blur_train,y_train_blur)\n",
    "loader(path_to_X_blur_test,x_test_blur) \n",
    "loader(path_to_Y_blur_test,y_test_blur)\n",
    "x_train_blur = np.stack(x_train_blur,axis=0)\n",
    "y_train_blur = np.stack(y_train_blur,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5413518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_blur = np.stack(x_test_blur,axis=0)\n",
    "y_test_blur = np.stack(y_test_blur,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a495750",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Noise Data\n",
    "x_train_noise,x_test_noise,y_train_noise,y_test_noise =[],[],[],[]\n",
    "loader(path_to_X_noise_train,x_train_noise)\n",
    "loader(path_to_Y_noise_train,y_train_noise)\n",
    "loader(path_to_X_noise_test,x_test_noise) \n",
    "loader(path_to_Y_noise_test,y_test_noise)\n",
    "x_train_noise = np.stack(x_train_noise,axis=0)\n",
    "y_train_noise = np.stack(y_train_noise,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9f402e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_noise = np.stack(x_test_noise,axis=0)\n",
    "y_test_noise = np.stack(y_test_noise,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7bbc1065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the Strach Data\n",
    "x_train_scratch,x_test_scratch,y_train_scratch,y_test_scratch =[],[],[],[]\n",
    "loader(path_to_X_scratch_train,x_train_scratch)\n",
    "loader(path_to_Y_scratch_train,y_train_scratch)\n",
    "loader(path_to_X_scratch_test,x_test_scratch) \n",
    "loader(path_to_Y_scratch_test,y_test_scratch)\n",
    "x_train_scratch = np.stack(x_train_scratch)\n",
    "y_train_scratch = np.stack(y_train_scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e56de109",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_scratch = np.stack(x_test_scratch)\n",
    "y_test_scratch = np.stack(y_test_scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45326df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading\n",
    "x_train_water,x_test_water,y_train_water,y_test_water =[],[],[],[]\n",
    "loader(path_to_X_water_train,x_train_water)\n",
    "loader(path_to_Y_water_train,y_train_water)\n",
    "loader(path_to_X_water_test,x_test_water) \n",
    "loader(path_to_Y_water_test,y_test_water)\n",
    "x_train_water = np.stack(x_train_water)\n",
    "y_train_water = np.stack(y_train_water)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b0911fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_water = np.stack(x_test_water)\n",
    "y_test_water = np.stack(y_test_water)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62bc566",
   "metadata": {},
   "source": [
    "## Importing required libraries for building CNN Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee769020",
   "metadata": {},
   "source": [
    "## Building CNN models for each of the possible damages to photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01cfcca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing TensorFlow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "681e616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Required layers for creation of CNN from TensofFlow.Keras\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Concatenate, UpSampling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06ecd2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the base Model from TensorFlow.Keras\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158d5bc3",
   "metadata": {},
   "source": [
    "### Utilizing Sequential Learning to train the model to deal with different types of Image deteriorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f032044",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a CNN model that can be used for all our datasets, i.e, to resolve Blurring,Scratches,Noise and Water-Spills\n",
    "def model_image_restore(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    #Encoder\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    # Bottleneck\n",
    "    b = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "\n",
    "    # Decoder\n",
    "    u1 = UpSampling2D((2, 2))(b)\n",
    "    concat1 = Concatenate()([u1, c2])\n",
    "    c3 = Conv2D(128, (3, 3), activation='relu', padding='same')(concat1)\n",
    "\n",
    "    u2 = UpSampling2D((2, 2))(c3)\n",
    "    concat2 = Concatenate()([u2, c1])\n",
    "    c4 = Conv2D(64, (3, 3), activation='relu', padding='same')(concat2)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = Conv2D(3, (1, 1), activation='sigmoid')(c4)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1b8665",
   "metadata": {},
   "source": [
    "## Model Compilation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "351a8453",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the CNN for restoring the images in our dataset by using our model_image_restore\n",
    "input_shape = (256,256,3) # the shape that every single input image has to be in to be fed to the CNN\n",
    "model_image_restore = model_image_restore(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c38b3f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compiling the model_unbur\n",
    "model_image_restore.compile(optimizer='adam',loss='mean_squared_error',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419f9c18",
   "metadata": {},
   "source": [
    "## Sequential Step 1 - Train the Model to Unblur the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e95ef10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "19/19 [==============================] - 376s 20s/step - loss: 0.0680 - accuracy: 0.6521 - val_loss: 0.0283 - val_accuracy: 0.7961\n",
      "Epoch 2/15\n",
      "19/19 [==============================] - 371s 20s/step - loss: 0.0171 - accuracy: 0.7633 - val_loss: 0.0142 - val_accuracy: 0.7842\n",
      "Epoch 3/15\n",
      "19/19 [==============================] - 370s 20s/step - loss: 0.0104 - accuracy: 0.7723 - val_loss: 0.0094 - val_accuracy: 0.8111\n",
      "Epoch 4/15\n",
      "19/19 [==============================] - 374s 20s/step - loss: 0.0079 - accuracy: 0.7922 - val_loss: 0.0077 - val_accuracy: 0.8201\n",
      "Epoch 5/15\n",
      "19/19 [==============================] - 371s 20s/step - loss: 0.0068 - accuracy: 0.8195 - val_loss: 0.0069 - val_accuracy: 0.8440\n",
      "Epoch 6/15\n",
      "19/19 [==============================] - 373s 20s/step - loss: 0.0068 - accuracy: 0.8286 - val_loss: 0.0067 - val_accuracy: 0.8482\n",
      "Epoch 7/15\n",
      "19/19 [==============================] - 372s 20s/step - loss: 0.0061 - accuracy: 0.8376 - val_loss: 0.0064 - val_accuracy: 0.8497\n",
      "Epoch 8/15\n",
      "19/19 [==============================] - 375s 20s/step - loss: 0.0057 - accuracy: 0.8318 - val_loss: 0.0062 - val_accuracy: 0.8359\n",
      "Epoch 9/15\n",
      "19/19 [==============================] - 375s 20s/step - loss: 0.0054 - accuracy: 0.8490 - val_loss: 0.0058 - val_accuracy: 0.8537\n",
      "Epoch 10/15\n",
      "19/19 [==============================] - 375s 20s/step - loss: 0.0053 - accuracy: 0.8439 - val_loss: 0.0057 - val_accuracy: 0.8421\n",
      "Epoch 11/15\n",
      "19/19 [==============================] - 374s 20s/step - loss: 0.0052 - accuracy: 0.8502 - val_loss: 0.0057 - val_accuracy: 0.8487\n",
      "Epoch 12/15\n",
      "19/19 [==============================] - 373s 20s/step - loss: 0.0050 - accuracy: 0.8638 - val_loss: 0.0054 - val_accuracy: 0.8415\n",
      "Epoch 13/15\n",
      "19/19 [==============================] - 375s 20s/step - loss: 0.0050 - accuracy: 0.8752 - val_loss: 0.0060 - val_accuracy: 0.8325\n",
      "Epoch 14/15\n",
      "19/19 [==============================] - 374s 20s/step - loss: 0.0050 - accuracy: 0.8650 - val_loss: 0.0054 - val_accuracy: 0.8747\n",
      "Epoch 15/15\n",
      "19/19 [==============================] - 374s 20s/step - loss: 0.0049 - accuracy: 0.8699 - val_loss: 0.0055 - val_accuracy: 0.9084\n"
     ]
    }
   ],
   "source": [
    "## Training the model_image_restore using our pre-processed data\n",
    "Training_unblur = model_image_restore.fit(x_train_blur,y_train_blur,epochs=15,batch_size=32,validation_split=0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02e311e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 36s 5s/step\n"
     ]
    }
   ],
   "source": [
    "## Testing the model_image_restore for blurry images\n",
    "unblur_outputs = model_image_restore.predict(x_test_blur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "451732d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 35s 4s/step - loss: 0.0054 - accuracy: 0.9159\n",
      "Test Accuraccy For Unblurring The Images: 91.59%\n"
     ]
    }
   ],
   "source": [
    "## To Find the loss and accuraccy of the predictions made by model_image_restore\n",
    "loss,accuracy_unblur = model_image_restore.evaluate(x_test_blur,y_test_blur)\n",
    "print(f\"Test Accuraccy For Unblurring The Images: {accuracy_unblur * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688cd809",
   "metadata": {},
   "source": [
    "## Sequential Step 2 - Train the Model to De-Noise the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c84a0537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "18/18 [==============================] - 426s 24s/step - loss: 0.0026 - accuracy: 0.7871 - val_loss: 0.0018 - val_accuracy: 0.7402\n",
      "Epoch 2/15\n",
      "18/18 [==============================] - 441s 24s/step - loss: 0.0017 - accuracy: 0.7829 - val_loss: 0.0013 - val_accuracy: 0.7113\n",
      "Epoch 3/15\n",
      "18/18 [==============================] - 422s 23s/step - loss: 0.0013 - accuracy: 0.8253 - val_loss: 0.0011 - val_accuracy: 0.8184\n",
      "Epoch 4/15\n",
      "18/18 [==============================] - 353s 20s/step - loss: 0.0011 - accuracy: 0.8217 - val_loss: 9.0953e-04 - val_accuracy: 0.8102\n",
      "Epoch 5/15\n",
      "18/18 [==============================] - 356s 20s/step - loss: 9.1059e-04 - accuracy: 0.8066 - val_loss: 8.3627e-04 - val_accuracy: 0.8131\n",
      "Epoch 6/15\n",
      "18/18 [==============================] - 356s 20s/step - loss: 9.4494e-04 - accuracy: 0.8068 - val_loss: 7.4394e-04 - val_accuracy: 0.7974\n",
      "Epoch 7/15\n",
      "18/18 [==============================] - 356s 20s/step - loss: 8.8345e-04 - accuracy: 0.8070 - val_loss: 7.8155e-04 - val_accuracy: 0.6615\n",
      "Epoch 8/15\n",
      "18/18 [==============================] - 355s 20s/step - loss: 7.2620e-04 - accuracy: 0.7764 - val_loss: 6.9354e-04 - val_accuracy: 0.6776\n",
      "Epoch 9/15\n",
      "18/18 [==============================] - 355s 20s/step - loss: 6.5970e-04 - accuracy: 0.7724 - val_loss: 6.2623e-04 - val_accuracy: 0.6813\n",
      "Epoch 10/15\n",
      "18/18 [==============================] - 359s 20s/step - loss: 6.2469e-04 - accuracy: 0.7846 - val_loss: 5.5574e-04 - val_accuracy: 0.7062\n",
      "Epoch 11/15\n",
      "18/18 [==============================] - 357s 20s/step - loss: 5.8930e-04 - accuracy: 0.7766 - val_loss: 8.3546e-04 - val_accuracy: 0.6966\n",
      "Epoch 12/15\n",
      "18/18 [==============================] - 356s 20s/step - loss: 6.2640e-04 - accuracy: 0.7839 - val_loss: 5.3200e-04 - val_accuracy: 0.6894\n",
      "Epoch 13/15\n",
      "18/18 [==============================] - 355s 20s/step - loss: 6.4835e-04 - accuracy: 0.7857 - val_loss: 7.2511e-04 - val_accuracy: 0.6451\n",
      "Epoch 14/15\n",
      "18/18 [==============================] - 355s 20s/step - loss: 6.2959e-04 - accuracy: 0.7796 - val_loss: 4.9801e-04 - val_accuracy: 0.6637\n",
      "Epoch 15/15\n",
      "18/18 [==============================] - 354s 20s/step - loss: 5.3731e-04 - accuracy: 0.7842 - val_loss: 4.7716e-04 - val_accuracy: 0.6664\n"
     ]
    }
   ],
   "source": [
    "## Training the model_image_restore using our pre-processed noisy data\n",
    "Training_denoise = model_image_restore.fit(x_train_noise,y_train_noise,epochs=15,batch_size=32,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6a515ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 36s 4s/step\n"
     ]
    }
   ],
   "source": [
    "## Testing the model_image_restore\n",
    "denoise_outputs = model_image_restore.predict(x_test_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95dd9180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 36s 4s/step - loss: 0.0421 - accuracy: 0.1680\n",
      "Test Accuraccy For De-Noising The Images: 16.80%\n"
     ]
    }
   ],
   "source": [
    "## To Find the loss and accuraccy of the predictions made by model_image_restore\n",
    "loss,accuracy_denoise = model_image_restore.evaluate(x_test_noise,y_test_noise)\n",
    "print(f\"Test Accuraccy For De-Noising The Images: {accuracy_denoise * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf0b3a2",
   "metadata": {},
   "source": [
    "## Sequential Step 3 -Train the Model to Repair the Scratches on the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7329993e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 412s 20s/step - loss: 0.0252 - accuracy: 0.5267 - val_loss: 0.0088 - val_accuracy: 0.7626\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 394s 20s/step - loss: 0.0045 - accuracy: 0.7383 - val_loss: 0.0028 - val_accuracy: 0.7326\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 391s 20s/step - loss: 0.0022 - accuracy: 0.8419 - val_loss: 0.0018 - val_accuracy: 0.8764\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 480s 24s/step - loss: 0.0016 - accuracy: 0.8811 - val_loss: 0.0014 - val_accuracy: 0.8874\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 487s 24s/step - loss: 0.0014 - accuracy: 0.8885 - val_loss: 0.0013 - val_accuracy: 0.8955\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 418s 21s/step - loss: 0.0012 - accuracy: 0.8678 - val_loss: 0.0012 - val_accuracy: 0.8765\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 403s 20s/step - loss: 0.0011 - accuracy: 0.8593 - val_loss: 0.0011 - val_accuracy: 0.8821\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 396s 20s/step - loss: 0.0011 - accuracy: 0.8670 - val_loss: 0.0010 - val_accuracy: 0.8852\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 397s 20s/step - loss: 0.0010 - accuracy: 0.8701 - val_loss: 0.0010 - val_accuracy: 0.8734\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 397s 20s/step - loss: 0.0010 - accuracy: 0.8679 - val_loss: 0.0010 - val_accuracy: 0.8881\n"
     ]
    }
   ],
   "source": [
    "## Training the model_image_restore using our pre-processed scratched image data\n",
    "Training_unscratch = model_image_restore.fit(x_train_scratch,y_train_scratch,epochs=10,batch_size=32,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e4118fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 38s 4s/step\n"
     ]
    }
   ],
   "source": [
    "## Testing the model_image_restore\n",
    "unscratch_outputs = model_image_restore.predict(x_test_scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff86dfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 40s 4s/step - loss: 0.0011 - accuracy: 0.8717\n",
      "Test Accuraccy For Un Scratching The Images: 87.17%\n"
     ]
    }
   ],
   "source": [
    "## To Find the loss and accuraccy of the predictions made by model_image_restore\n",
    "loss,accuracy_unscratch = model_image_restore.evaluate(x_test_scratch,y_test_scratch)\n",
    "print(f\"Test Accuraccy For Un Scratching The Images: {accuracy_unscratch * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b149c23",
   "metadata": {},
   "source": [
    "## Sequential Step 4 - Train the Model to Repair Water-Spilled Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2633a1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 404s 20s/step - loss: 0.0122 - accuracy: 0.8270 - val_loss: 0.0096 - val_accuracy: 0.8413\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 399s 20s/step - loss: 0.0081 - accuracy: 0.8590 - val_loss: 0.0073 - val_accuracy: 0.8412\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 398s 20s/step - loss: 0.0068 - accuracy: 0.8604 - val_loss: 0.0065 - val_accuracy: 0.8665\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 395s 20s/step - loss: 0.0058 - accuracy: 0.8699 - val_loss: 0.0060 - val_accuracy: 0.8767\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 394s 20s/step - loss: 0.0059 - accuracy: 0.8728 - val_loss: 0.0066 - val_accuracy: 0.8623\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 391s 20s/step - loss: 0.0060 - accuracy: 0.8627 - val_loss: 0.0057 - val_accuracy: 0.8620\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 392s 20s/step - loss: 0.0052 - accuracy: 0.8760 - val_loss: 0.0052 - val_accuracy: 0.8780\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 397s 20s/step - loss: 0.0053 - accuracy: 0.8808 - val_loss: 0.0050 - val_accuracy: 0.8747\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 398s 20s/step - loss: 0.0058 - accuracy: 0.8758 - val_loss: 0.0060 - val_accuracy: 0.8315\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 394s 20s/step - loss: 0.0051 - accuracy: 0.8599 - val_loss: 0.0051 - val_accuracy: 0.8549\n"
     ]
    }
   ],
   "source": [
    "## Training the model_image_restore using our pre-processed water_spill image data\n",
    "Training_despill = model_image_restore.fit(x_train_water,y_train_water,epochs=10,batch_size=32,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "84ed472d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 39s 4s/step\n"
     ]
    }
   ],
   "source": [
    "## Testing the model_image_restore\n",
    "despill_outputs = model_image_restore.predict(x_test_water)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e11ee387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 39s 4s/step - loss: 0.0048 - accuracy: 0.8507\n",
      "Test Accuraccy For De Spilling The Images: 85.07%\n"
     ]
    }
   ],
   "source": [
    "## To Find the loss and accuraccy of the predictions made by model_image_restore\n",
    "loss,accuracy_despill = model_image_restore.evaluate(x_test_water,y_test_water)\n",
    "print(f\"Test Accuraccy For De Spilling The Images: {accuracy_despill * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cfa394b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving the model weights\n",
    "model_image_restore.save_weights('saved_weights_of_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "70963d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving the Entire Model\n",
    "model_image_restore.save('path_to_saved_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f0855c",
   "metadata": {},
   "source": [
    "## Data Post - Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9ab91219",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a Size Finding Helper Function that will help post-processing by providing it with the original size of the image in question.\n",
    "def SizeFinder(count,Index_Name):\n",
    "    Indx = Index_Name[1][count]\n",
    "    Sizes = Index_Name[0]\n",
    "    return [Sizes[Indx],Indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e5f819f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting the output images from the CNN models into their original forms, i.e, De-Normalizing the images then Resizing them.\n",
    "Sample_Restored = []\n",
    "def restorer(model_output,RestoredStorer,Index_Name):\n",
    "    count=0 #maintaing the count to find the associated original size for resizing purposes\n",
    "    for image in model_output:\n",
    "        #De-Normalizing the image back from 0,1's\n",
    "        de_normalized = (image*255).astype('uint8') \n",
    "        #Obtaining the Original_Sizes\n",
    "        actual_size = SizeFinder(count,Index_Name) #Calling the Function that will return the original size of the image being processed\n",
    "        Indx_number = actual_size[1]\n",
    "        actual_width = actual_size[0][1] #Taking the actual_width of the image to pass through the resize function\n",
    "        actual_height = actual_size[0][0] #Taking the actual_height of the image to pass through the resize function\n",
    "        ##Resizing to Original Dimensions\n",
    "        resized = cv2.resize(image,(actual_width,actual_height))\n",
    "        #Storing this De-Normalized and Resized Image\n",
    "        RestoredStorer.append(resized)\n",
    "        count+=1 # Incrementing the count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d60b8b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Indexes\n",
    "import pickle\n",
    "with open('lists.pkl','rb') as f:\n",
    "    Index_Blur,Index_Noise,Index_Scratch,Index_Water = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fbe13da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##passing the model_unblur_outputs through the post-processing functions\n",
    "Unblurred = [] #To store the post-processed Output Images\n",
    "restorer(model_unblur_outputs,Unblurred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c4864883",
   "metadata": {},
   "outputs": [],
   "source": [
    "##passing the model_denoise_outputs through the post-processing functions\n",
    "De_Noised = [] #To store the post-processed Output Images\n",
    "restorer(model_denoise_outputs,De_Noised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d632a317",
   "metadata": {},
   "outputs": [],
   "source": [
    "##passing the model_unscratch_outputs through the post-processing functions\n",
    "Un_Scratch = [] #To store the post-processed Output Images\n",
    "restorer(model_unscratch_outputs,Un_Scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0d321117",
   "metadata": {},
   "outputs": [],
   "source": [
    "##passing the model_despill_outputs through the post-processing functions\n",
    "De_Spill = [] #To store the post-processed Output Images\n",
    "resotrer(model_despill_outputs,De_Spill)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8509fe9",
   "metadata": {},
   "source": [
    "## Saving the Restored Images in Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "82f56e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Already Imported the Required Libraries at the start\n",
    "## first create path to the saving folder\n",
    "#writing a function to creation of save folders\n",
    "def folder_creation(path_to_folder):\n",
    "    if os.path.exists(path_to_folder):\n",
    "        shutil.rmtree(path_to_folder)\n",
    "    shutil.mkdir(path_to_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c6d09e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "##using the folder_creation function to create a saving folder for Unblurred photos outputter by the CNN Model\n",
    "path_to_unblur = './data/Unblurred'\n",
    "folder_creation(path_to_unblur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5a97b69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##using the folder_creation function to create a saving folder for De_Noised photos outputter by the CNN Model\n",
    "path_to_denoise = './data_noise/De_Noised'\n",
    "folder_creation(path_to_denoise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dc306529",
   "metadata": {},
   "outputs": [],
   "source": [
    "##using the folder_creation function to create a saving folder for Un_Scratched photos outputter by the CNN Model\n",
    "path_to_unscratch = './data_scratch/Un_Scratched'\n",
    "folder_creation(path_to_unscratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "45ec7a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##using the folder_creation function to create a saving folder for De_Spilled photos outputter by the CNN Model\n",
    "path_to_despill='./data_waterspilled/De_Spill'\n",
    "folder_creation(path_to_despill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "22dad59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing a function to save the restored images\n",
    "def saver(outputs,path_to_save,category_name):\n",
    "    count = 0 #Maintaing the count, useful in naming the files to be saved\n",
    "    for image in outputs:\n",
    "        img = Image.fromarray(image) #converting the np.array into an Image to be saved into a folder\n",
    "        names=path_to_save.split()\n",
    "        saving_name = category_name + str(count) + '.jpg' #creating the name of the file to be saved in the folder\n",
    "        img.save(os.path.join(path_to_save,saving_name))\n",
    "        count+=1 #Incrementing the count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "db61d9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## saving the unblurred images by passing through the saver function\n",
    "saver(Unblurred,path_to_unblur,'Unblur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8fafdd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "##saving the De-Noised images by passing through the saver function\n",
    "saver(De_Noised,path_to_denoise,'De_Noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e96aa42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##saving the Un_Scratched images by passing through the saver function\n",
    "saver(Un_Scratched,path_to_unscratch,'Un_Scratch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0d178e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "##saving the De_Spilled images by passing through the saver function\n",
    "saver(De_Spill,path_to_despill,'De_Spill')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
